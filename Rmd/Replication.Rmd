---
title: "Replication"
author: "Mikkel Roald-Arb√∏l"
date: "9/19/2020"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r functions, include=FALSE}
# Compute time ----
f2s <- function(frame){
  time <- frame * (1/input$rate)
  return(time)
}

# Local maxima and minima ----
localMaxima <- function(x) which(x - data.table::shift(x, 1) > 0  & x - data.table::shift(x, 1, type='lead') > 0)
localMinima <- function(x) which(x - data.table::shift(x, 1) < 0  & x - data.table::shift(x, 1, type='lead') < 0)

# Find closest value - either smaller, bigger or absolute ----
smaller <- function(x, value) which.min(abs(value - replace(x, x>value, Inf)))
bigger <- function(x, value) which.max(abs(value - replace(x, x>value, Inf)))
closest<-function(x, value){
  x[which(abs(x - value) == min(abs(x - value)))] 
}

# Smooth data ----
smooth_it <- function(data, xvar, yvar, smooth.cons){
  df <- list()
  df.Smooth <- list()
  
  for (i in 1:length(data)){
    df[[i]] <- smooth.spline(data[[i]][[yvar]], spar = smooth.cons)
    df.Smooth[[i]] <- tibble(.rows = length(df[[i]]$y))
    df.Smooth[[i]]$yvar <- df[[i]]$y
    df.Smooth[[i]]$xvar <- data[[i]]$xvar
    if (!is.null(data[[i]]$minute)){
      df.Smooth[[i]]$minute <- data[[i]]$minute
    }
  }
  return(df.Smooth)
}

# Long function that does all the work! ----
wrangle_data <- function(data, x, y, fps, smooth, smooth.cons, invert, which, rm.duplicates, min.height, threshold, thres.type, remove, info) {
  
  dataFiles <- data
  
  if (class(dataFiles) != 'list'){
    dataFiles <- list(dataFiles)
  }

  for (i in 1:length(dataFiles)){
    dataFiles[[i]] <- dataFiles[[i]] %>%
      mutate(Time = row_number()/fps,
             minute = i) 
    dataFiles[[i]]$yvar <- dataFiles[[i]][[y]]
    dataFiles[[i]]$xvar <- dataFiles[[i]][[x]]
    
    # Remove a whole column of NA's
    col.remove <- c()
    for (j in 1:length(dataFiles[[i]])){
      if (all(is.na(dataFiles[[i]][j]))){
        col.remove <- c(col.remove, j)
      }
    }
    dataFiles[[i]][col.remove] <- list(NULL)
    
    # Remove remaining NA observations
    dataFiles[[i]] <- na.exclude(dataFiles[[i]])
  }
  

  # Inverting ----
  raw_summary <- list()
  if (invert == TRUE){
    for (i in 1:length(dataFiles)){
      raw_summary[[i]] <- tibble()  
      raw_summary[[i]] <- dataFiles[[i]] %>%
        summarise(value.max = max(abs(yvar)),
                  value.min = min(abs(yvar)),
                  val.mid = value.max - (value.max - value.min)/2)
    }
    
    for (i in as.numeric(which)){
      signs <- sign(mean(dataFiles[[i]]$yvar))
      dataFiles[[i]]$yvar <- ((-(dataFiles[[i]]$yvar - (signs * raw_summary[[i]]$val.mid))) + (signs * raw_summary[[i]]$val.mid))
    }
  }
  
  
  # Data smoothing ----
  if (smooth == TRUE){
    df.Smooth <- smooth_it(dataFiles, 'xvar', 'yvar', smooth.cons)
  } else {
    df.Smooth <- dataFiles
  }
  
  
  # 4.Find spike timing and rate ----
  peaks <- list()
  troughs <- list()
  spike_timing <- list()
  spike_summary.list <- list()
  spike_summary <- tibble()
  
  for (i in 1:length(dataFiles)){
    peaks[[i]] <- tibble()
    peaks[[i]] <- localMaxima(df.Smooth[[i]]$yvar)
    troughs[[i]] <- tibble()
    troughs[[i]] <- localMaxima(-df.Smooth[[i]]$yvar)
    spike_timing[[i]] <- tibble(.rows = length(peaks[[i]]))
    spike_timing[[i]]$peak_time <- df.Smooth[[i]]$xvar[peaks[[i]]]
    spike_timing[[i]]$peak <- df.Smooth[[i]]$yvar[peaks[[i]]]
    spike_timing[[i]]$trough_time_before <- NA
    spike_timing[[i]]$trough_time_after <- NA
    spike_timing[[i]]$min_spike_height <- NA
    spike_timing[[i]]$max_spike_height <- NA
    spike_timing[[i]]$mean_spike_height <- NA
    
    # Long piece for finding the troughs on either side of a peak
    for (j in 1:length(peaks[[i]])){
      if (!is_empty(troughs[[i]][troughs[[i]]<peaks[[i]][j]])){
        l.sel <- troughs[[i]][troughs[[i]]<peaks[[i]][j]]
        l <- closest(l.sel, peaks[[i]][j])
        spike_timing[[i]]$trough_time_before[j] <- df.Smooth[[i]]$xvar[l]
      }
      
      if (!is_empty(troughs[[i]][troughs[[i]]>peaks[[i]][j]])){
        u.sel <- troughs[[i]][troughs[[i]]>peaks[[i]][j]]
        u <- closest(u.sel, peaks[[i]][j])
        spike_timing[[i]]$trough_time_after[j] <- df.Smooth[[i]]$xvar[u]
      }
      
      # Prerequisite for selection based on spike height
      which.before <- which(df.Smooth[[i]]$xvar == spike_timing[[i]]$trough_time_before[j])
      which.after <- which(df.Smooth[[i]]$xvar == spike_timing[[i]]$trough_time_after[j])
      h.before <- df.Smooth[[i]]$yvar[which.before]
      h.after <- df.Smooth[[i]]$yvar[which.after]
      peak <- spike_timing[[i]]$peak[j]
      spike_timing[[i]]$min_spike_height[j] <- min(c((peak-h.before), (peak-h.after)))
      spike_timing[[i]]$max_spike_height[j] <- max(c((peak-h.before), (peak-h.after)))
      spike_timing[[i]]$mean_spike_height[j] <- (max(c((peak-h.before), (peak-h.after))) + min(c((peak-h.before), (peak-h.after))))/2
    }
    
    # Find half width 
    spike_timing[[i]] <- spike_timing[[i]] %>%
      mutate(half_time = trough_time_before + (peak_time - trough_time_before)/2)
    
    if (nrow(spike_timing[[i]]) > 0){
      for (j in 1:nrow(spike_timing[[i]])){
        if (!is.na(spike_timing[[i]]$half_time[[j]])){
          suppressWarnings(spike_timing[[i]]$half_time[j] <- closest(df.Smooth[[i]]$xvar, spike_timing[[i]]$half_time[j]))
          suppressWarnings(spike_timing[[i]]$half_height[j] <- df.Smooth[[i]]$yvar[which(df.Smooth[[i]]$xvar == spike_timing[[i]]$half_time[j])])
          l <- which(df.Smooth[[i]]$xvar == spike_timing[[i]]$peak_time[j])
          u <- which(df.Smooth[[i]]$xvar == spike_timing[[i]]$trough_time_after[j])
          if (!is_empty(l) & !is_empty(u)){
            sel <- df.Smooth[[i]][l:u,]
            close <- sel$yvar[smaller(sel$yvar, spike_timing[[i]]$half_height[[j]])]
            half_after_time <- sel$xvar[sel$yvar == close]
            suppressWarnings(spike_timing[[i]]$half_width[j] <- (half_after_time - spike_timing[[i]]$half_time[[j]]))
          } else {
            suppressWarnings(spike_timing[[i]]$half_width[j] <- NA)
          }
        } else {
          suppressWarnings(spike_timing[[i]]$half_height[j] <- NA)
          suppressWarnings(spike_timing[[i]]$half_width[j] <- NA)
        }
      }
      
      get_rid_of <- c('half_time', 'half_height')
      spike_timing[[i]] <- spike_timing[[i]][,!(names(spike_timing[[i]]) %in% get_rid_of)]
    }
  }
  
  # Filter out spikes ----
  #' Filters out rogue spikes in 3 ways:
  #' 1. The height of the shortest slope of the spike > min.height.
  #' 2. Removes duplicate spikes.
  #' 3. By introducing a universal threshold that spike peaks must exceed.
  #' 
  
  # Thresholding prereq.
  for (i in 1:length(dataFiles)){  
    
    # By spike height - gets rid of small squiggly spikes
    spike_timing[[i]] <- spike_timing[[i]] %>%
      filter(spike_timing[[i]]$max_spike_height > min.height)
    
    # Choose 1 of two adjacent spikes
    if (rm.duplicates == TRUE){
      need.remove <- c()
      if (nrow(spike_timing[[i]]) > 0){
        for (j in 1:(nrow(spike_timing[[i]])-1)){
          if (spike_timing[[i]]$trough_time_after[j] == spike_timing[[i]]$trough_time_before[j+1] 
              && spike_timing[[i]]$mean_spike_height[j] < min.height
              && spike_timing[[i]]$mean_spike_height[j+1] < min.height
          ){
            lowest <- which.min(c(spike_timing[[i]]$peak[j], spike_timing[[i]]$peak[j+1]))
            which.rm <- ifelse(lowest == 1, j, j+1)
            need.remove <- c(need.remove, which.rm)
          }
        }
        
        if (!is.null(need.remove)){
          spike_timing[[i]] <- spike_timing[[i]][-need.remove,]
        }
      }
    }
    
    
    
    # By threshold
    raw_summary[[i]] <- tibble()  
    raw_summary[[i]] <- dataFiles[[i]] %>%
      summarise(value.max = max(yvar),
                value.min = min(yvar),
                value.mean = mean(yvar))
    
    if (thres.type == "Mean"){
      spike_timing[[i]] <- spike_timing[[i]] %>%
        filter(spike_timing[[i]]$peak > (raw_summary[[i]]$value.mean + threshold))
    } else if (thres.type == "Minimum"){
      spike_timing[[i]] <- spike_timing[[i]] %>%
        filter(spike_timing[[i]]$peak > (raw_summary[[i]]$value.min + threshold))
    }
  }
  
  # Remove specified peaks
  need.remove <- list()
  t <- as.numeric(unlist(regmatches(remove, gregexpr("(?>-)*[[:digit:]]+\\.*[[:digit:]]*", remove, perl=TRUE))))
  t <- unique(unlist(lapply(t, function(x) as.integer(x))))
  for (i in t){
    # Modified solution from https://stackoverflow.com/questions/19252663/extracting-decimal-numbers-from-a-string
    need.remove[[i]] <- unlist(regmatches(remove,gregexpr(paste0(i, "+\\.[[:digit:]]*"), remove)))
    vector.temp <- vector()
    for (j in 1:length(need.remove[[i]])){
      df.temp <- unlist(strsplit(need.remove[[i]][[j]], split='.', fixed=TRUE))
      vector.temp <- c(vector.temp, as.numeric(df.temp[2]))
    }
    need.remove[[i]] <- sort(vector.temp)
    if (nrow(spike_timing[[i]]) > 0){
      spike_timing[[i]] <- spike_timing[[i]] %>%
      filter(!row_number() %in% need.remove[[i]])
    }
  }
  
  # Finish by calculating spike rate
  for (i in 1:length(spike_timing)){
    spike_timing[[i]] <- spike_timing[[i]] %>%
      mutate(spike_rate = 1/(peak_time - lag(peak_time)))
  }
  
  

  
  # Spike summary list ----
  for (i in 1:length(spike_timing)){
    if (nrow(spike_timing[[i]] > 0)){
      spike_summary.list[[i]] <- spike_timing[[i]] %>%
        summarise(SpikeRate_mean = mean(spike_rate, na.rm = TRUE),
                  SpikeRate_SD = sd(spike_rate, na.rm = TRUE),
                  HalfWidth_mean = mean(half_width, na.rm = TRUE),
                  HalfWidth_SD = sd(half_width, na.rm = TRUE)
        ) %>%
        mutate(minute = i)
      spike_summary <- bind_rows(spike_summary, spike_summary.list[[i]])
    }
  }
  
  for (i in 1:length(dataFiles)){
    if (!any(spike_summary$minute == i)){
      spike_summary[(nrow(spike_summary)+1), ] <- NA
      spike_summary[nrow(spike_summary), 'minute'] <- i
      spike_summary <- spike_summary %>%
        arrange(minute)
    }
  }
  
  for (i in 1:length(dataFiles)){
    dataFiles[[i]] <- dataFiles[[i]] %>%
      mutate(peak = if_else(xvar %in% spike_timing[[i]]$peak_time, 
                            xvar, 
                            0))
  }
  

  
  # Prepare a smooth file for plotting
  dataSmooth <- list()
  for (i in 1:length(dataFiles)){
    dataSmooth[[i]] <- dataFiles[[i]] %>%
      mutate(xvar = df.Smooth[[i]]$xvar,
             yvar = df.Smooth[[i]]$yvar)
  }
  
  # Make spike timing file
  spike_timing_all <- data.frame()
  spike_timing_all <- bind_rows(spike_timing_all, spike_timing)
  
  # Make metadata file
  if (is.null(dataFiles[[1]]$BX)){
    metadata <- data.frame()
  } else {
    metadata <- data.frame()
    for (i in 1:length(dataFiles)){
      current.metadata <- tibble()
      current.metadata <- dataFiles[[i]] %>%
        select(BX, BY, Width, Height) %>%
        slice(1) %>%
        mutate(minute = i,
               smooth = smooth,
               smooth.cons = smooth.cons,
               threshold.type = thres.type,
               threshold = threshold,
               inverted = if_else(invert == TRUE & i %in% which, "Yes", "No", missing="No"),
               rm.duplicates = rm.duplicates,
               min.height = min.height,
               removed = if_else(remove == '', remove, "none")
        )
    metadata <- bind_rows(metadata, current.metadata)
    }
  }
  
  output <- list(dataFiles, dataSmooth, spike_summary, spike_timing_all, metadata)
  
  if (info != ''){
    # Add experimental info to all data sets ----
    descript <- unlist(strsplit(info, ',')) # First extract individual strings from expression
    
    # dataFiles
    for (i in 1:length(dataFiles)){
      for (j in 1:length(descript)){
        name <- paste0('info', j)
        dataFiles[[i]] <- dataFiles[[i]] %>%
          mutate({{name}} := descript[[j]]) # Double curly braces from {{rlang}} paired with := for looping variable names
      }
    }
    
    # dataSmooth
    for (i in 1:length(dataSmooth)){
      for (j in 1:length(descript)){
        name <- paste0('info', j)
        dataSmooth[[i]] <- dataSmooth[[i]] %>%
          mutate({{name}} := descript[[j]]) # Double curly braces from {{rlang}} paired with := for looping variable names
      }
    }
    
    # Remaining data.frames
    for (i in 3:length(output)){
      for (j in 1:length(descript)){
        name <- paste0('info', j)
        output[[i]] <- output[[i]] %>%
          mutate({{name}} := descript[[j]]) # Double curly braces from {{rlang}} paired with := for looping variable names
      }
    }
  }
  return(output)
}

# Make plot ----
spike_plot <- function(data, xvar, yvar, threshold){

  df.All <- tibble()
  for (i in 1:length(data)){
    df.All <- bind_rows(df.All, data[[i]])
  }
  
  df.All <- df.All %>%
    mutate(peak = if_else(peak == 0, NA_real_, peak))
  
  xmax <- max(df.All$xvar)
  ymax <- max(df.All$yvar)
  
    ggplot(df.All, aes(x=xvar, y = yvar)) +
      geom_line() +
      #geom_rug(aes(peak), sides = "b") +
      geom_vline(data = df.All, aes(xintercept = peak),
                 alpha = .5,
                 colour = "orange",
                 linetype = 2,
                 show.legend = FALSE) +
      scale_x_continuous(limits = c(0,xmax),
                         breaks = seq(0,xmax,1)
      ) +
      labs(x = "Time (s)",
           y = paste("Image", yvar, "/ Cardiac contraction"),
           title = "") +
      facet_wrap(~ minute, nrow = 1) + #, scales = "free_y") +
      theme(panel.background = element_blank(),
            panel.grid = element_blank(),
            legend.key = element_rect(colour = "black"),
            legend.justification = c(1,0),
            legend.position = c(.27,.84),
            axis.line.x.bottom = element_line(colour = "black", size = .7),
            axis.line.y.left = element_line(colour = "black", size = .7),
            text = element_text(family = "serif", size = 10),
            aspect.ratio = 4/5
      ) -> plot
  return(plot)
}
```

This R Markdown document is made interactive using Shiny. Unlike the more traditional workflow of creating static reports, you can now create documents that allow your readers to change the assumptions underlying your analysis and see the results immediately. 

To learn more, see [Interactive Documents](http://rmarkdown.rstudio.com/authoring_shiny.html).

## Inputs and Outputs

You can embed Shiny inputs and outputs in your document. Outputs are automatically updated whenever inputs change.  This demonstrates how a standard R plot can be made interactive by wrapping it in the Shiny `renderPlot` function. The `selectInput` and `sliderInput` functions create the input widgets used to drive the plot.

```{r dataInput, echo=TRUE}
inputPanel(
  fileInput("files", "Choose Data Files",
                         multiple = TRUE,
                         accept = c(
                             "text/csv",
                             "text/comma-separated-values,text/plain",
                             ".csv", '.xlsx')
  )
)
```

## Embedded Application

It's also possible to embed an entire Shiny application within an R Markdown document using the `shinyAppDir` function. This example embeds a Shiny application located in another directory:

```{r tabsets, echo=FALSE}
shinyAppDir(
  system.file("examples/06_tabsets", package = "shiny"),
  options = list(
    width = "100%", height = 550
  )
)
```

Note the use of the `height` parameter to determine how much vertical space the embedded application should occupy.

You can also use the `shinyApp` function to define an application inline rather then in an external directory.

In all of R code chunks above the `echo = FALSE` attribute is used. This is to prevent the R code within the chunk from rendering in the document alongside the Shiny components.



